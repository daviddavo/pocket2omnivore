{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "2IrD-ZoJQAPD"
   },
   "source": [
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/daviddavo/pocket2omnivore/HEAD?labpath=pocket2omnivore.ipynb)\n",
    "\n",
    "> This notebook is part of the [How to export your Pocket data and migrate to Omnivore](https://blog.ddavo.me/posts/tutorials/pocket-to-omnivore) tutorial\n",
    "\n",
    "# 1. Upload, parse, and store the Pocket File. \n",
    "\n",
    "First, let upload the `ril_export.html` file generated in https://getpocket.com/export\n",
    "\n",
    "The html has the following extructure:\n",
    "\n",
    "- `<h1>` Unread\n",
    "- `<ul>` with list items of `<a>`. The href is the link to the article, and the anchor text is the title. It also has a `tags` and `time_added` attributes.\n",
    "- `<h1>` Read\n",
    "- Another `<ul>` like the one above\n",
    "\n",
    "We will transform this into a dict of: \n",
    "- *read*: Boolean on wether the article has been read\n",
    "- *time_added*: The time the item was added\n",
    "- *tags*: An array of strings\n",
    "- *href*: The url\n",
    "- *title*: The title of the article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "ez79reGjPokG",
    "outputId": "13422d0c-3dff-40ff-b0aa-c43fad089867",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ipywidgets import FileUpload\n",
    "from IPython.display import display\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "upload = FileUpload(accept='.html', multiple=False)\n",
    "\n",
    "def save_file():\n",
    "    for v in upload.value:\n",
    "        content = v['content']\n",
    "        with open(v['name'], 'wb') as f:\n",
    "            f.write(bytes(content))\n",
    "\n",
    "upload.observe(save_file, names='value')\n",
    "\n",
    "display(upload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert Path(\"ril_export.html\").exists(), \"Upload the file before continue running\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wEUX9qenQIBM",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "OMNIVORE_API_URL = \"https://api-prod.omnivore.app/api/graphql\"\n",
    "# The API key will have the following format \"00000000-0000-0000-0000-000000000000\"\n",
    "OMNIVORE_API_KEY = os.environ.get('OMNIVORE_API_KEY')\n",
    "SCHEMA_URL = \"https://raw.githubusercontent.com/omnivore-app/omnivore/c9fcbe72ddc6f40dd06e7073b8ffe3c1e71bd650/packages/api/src/generated/schema.graphql\"\n",
    "REQUESTS_SLEEP_TIME = 60 # Number of seconds\n",
    "PARALLEL_API_CALL_SIZE = 4\n",
    "\n",
    "if not OMNIVORE_API_KEY:\n",
    "    OMNIVORE_API_KEY=input('Enter your omnivore API key (should have a format similar to 00000000-0000-0000-0000-000000000000)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ka7QucTeQUFs",
    "outputId": "c85f5ad9-a75e-4a47-fa7b-e26c7c1313f5"
   },
   "outputs": [],
   "source": [
    "with open('ril_export.html', 'r') as f:\n",
    "    soup = BeautifulSoup(f, 'html.parser')\n",
    "\n",
    "soup.title"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the articles and tags from the HTML doc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IEYZUjJFRshV"
   },
   "outputs": [],
   "source": [
    "def process_list(h1):\n",
    "    ul = h1.find_next_sibling('ul')\n",
    "    print(len(ul), h1.text, 'articles')\n",
    "    read = h1.text != 'Unread'\n",
    "\n",
    "    items = []\n",
    "    for a in ul.findAll('a', href=True):\n",
    "        items.append({\n",
    "            'read': read,\n",
    "            'time_added': datetime.fromtimestamp(int(a['time_added'])),\n",
    "            'href': a['href'],\n",
    "            'tags': a['tags'].split(','),\n",
    "            'title': a.text,\n",
    "        })\n",
    "\n",
    "    return items\n",
    "\n",
    "articles = [item for sublist in [process_list(h1) for h1 in soup.findAll('h1')] for item in sublist]\n",
    "labels = set([item for sublist in [article['tags'] for article in articles if article['tags'][0] != ''] for item in sublist])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Store the articles and tags in a SQLLite Database\n",
    "\n",
    "We want to be able to track our process, as the API for Omnivore has rate limiting, and takes a while to upload the files. For this we will use a SQL Database.\n",
    "\n",
    "We will store the Articles in the format: \n",
    "- *read*: Boolean on wether the article has been read\n",
    "- *time_added*: The time the item was added\n",
    "- *tags*: An array of strings\n",
    "- *href*: The url\n",
    "- *id*: nullable field that stores the omnivore file.\n",
    "\n",
    "and the tags with:\n",
    "- *name*: Name of the tag \n",
    "- *id*: if the tag has been stored. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect('omnivore.db')\n",
    "\n",
    "# Create a cursor object to execute SQL commands\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Create the Article Table \n",
    "cursor.execute('''CREATE TABLE IF NOT EXISTS articles (\n",
    "                    id TEXT nullable,\n",
    "                    read BOOLEAN,\n",
    "                    time_added TEXT,\n",
    "                    tags TEXT, \n",
    "                    href TEXT PRIMARY KEY \n",
    "                )''')\n",
    "\n",
    "cursor.execute('''CREATE TABLE IF NOT EXISTS tags (\n",
    "                    id TEXT nullable,\n",
    "                    name TEXT PRIMARY KEY\n",
    "                )''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "insert_tag_sql = f\"\"\"INSERT OR IGNORE into tags (name) values (?)\"\"\"\n",
    "cursor.executemany(insert_tag_sql, [(label,) for label in labels])\n",
    "\n",
    "insert_article_sql = f\"INSERT OR IGNORE into articles (read, time_added, href, tags) values (?,?,?,?)\"\n",
    "article_values = [(article['read'], article['time_added'].isoformat(), article['href'], json.dumps(article['tags'])) for article in articles]\n",
    "cursor.executemany(insert_article_sql, article_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ei9PTNIzawUo",
    "outputId": "e0adcbcd-278e-4d3f-d5c2-c5db0c9c3de7"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "with requests.get(SCHEMA_URL) as r:\n",
    "    r.raise_for_status()\n",
    "    schema = r.text\n",
    "\n",
    "    assert schema is not None\n",
    "\n",
    "print(schema[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vIQr1xQ9fq-W"
   },
   "outputs": [],
   "source": [
    "from gql import gql, Client\n",
    "from gql.transport.requests import RequestsHTTPTransport\n",
    "\n",
    "def create_client():\n",
    "    transport = RequestsHTTPTransport(\n",
    "       url=OMNIVORE_API_URL,\n",
    "        headers = {\n",
    "            'authorization': OMNIVORE_API_KEY,\n",
    "        }\n",
    "    )\n",
    "    return Client(transport=transport, schema=schema, fetch_schema_from_transport=False, execute_timeout=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sJNbK-UaBr0-",
    "outputId": "555ac6ee-8e64-431f-928c-475f8a1a8d02"
   },
   "outputs": [],
   "source": [
    "# Doing a \"test query\" to check if everything is correct\n",
    "\n",
    "with create_client() as session: \n",
    "    r = session.execute(gql(\"\"\"\n",
    "    query Viewer {\n",
    "        me {\n",
    "            id\n",
    "            name\n",
    "            profile {\n",
    "                username\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \"\"\"))\n",
    "\n",
    "    result = r\n",
    "    USERNAME = result['me']['profile']['username']\n",
    "\n",
    "    print(f\"Hello {result['me']['name']} ({USERNAME})!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_to_tag(row):  \n",
    "   return { \n",
    "      \"name\": row[1],\n",
    "      \"id\": row[0]\n",
    "   }\n",
    "\n",
    "def getExistingTags():\n",
    "  with create_client() as session: \n",
    "    r = session.execute(gql(\"\"\"\n",
    "    query Labels {\n",
    "        labels {\n",
    "              ...on LabelsSuccess { \n",
    "                  labels { name, id }\n",
    "              }\n",
    "          }\n",
    "    }\n",
    "    \"\"\"))\n",
    "\n",
    "    result = r\n",
    "    return result['labels']['labels']\n",
    "\n",
    "#Then remove all the tags from the ones we created before\n",
    "def saveTags(tagName): \n",
    "    with create_client() as client: \n",
    "      mutation = \"\"\"\n",
    "      mutation ($name: String!) {{\n",
    "        createLabel(input: {{color: \"#000\", name: $name }}) {{\n",
    "          ... on CreateLabelSuccess {{\n",
    "            label {{\n",
    "              id\n",
    "              name\n",
    "              color\n",
    "              description\n",
    "              createdAt\n",
    "            }}\n",
    "          }}\n",
    "          ... on CreateLabelError {{\n",
    "            errorCodes\n",
    "          }}\n",
    "        }}\n",
    "      }}\n",
    "      \"\"\"\n",
    "      r = client.execute(gql(mutation), {'name': tagName})\n",
    "      print(r)\n",
    "      return r['createLabel']['label']['id']\n",
    "\n",
    "server_tags = getExistingTags()\n",
    "all_tags = [row_to_tag(row) for row in cursor.execute('select * from tags').fetchall()]\n",
    "unsaved_tags = list(filter(lambda row: row['id'] is None, all_tags))\n",
    "presaved_tags = list(filter(lambda row: row['id'] is not None, all_tags))\n",
    "\n",
    "tagIds = {f\"{dictionary['name']}\": dictionary[\"id\"] for dictionary in presaved_tags + server_tags}\n",
    "for tagValue in unsaved_tags: \n",
    "    if tagValue[\"name\"] not in tagIds:\n",
    "      try:\n",
    "          tag = tagValue['name']\n",
    "          id = saveTags(tag)\n",
    "          tagIds[tag] = id\n",
    "      except Exception as e:\n",
    "          print(\"An error occurred:\", e)\n",
    "\n",
    "\n",
    "query = \"UPDATE tags SET id = ? where name = ?\"\n",
    "cursor.executemany(query, [(value, key) for key, value in tagIds.items()])\n",
    "\n",
    "tagIds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kxdnsdP4hYA8",
    "outputId": "16a47c1a-dee1-4fdf-d6d3-74ee2add63b1"
   },
   "outputs": [],
   "source": [
    "import backoff\n",
    "\n",
    "createArticle = gql(\"\"\"\n",
    "  mutation CreateArticleSavingRequest($url: String!) {\n",
    "    createArticleSavingRequest(input: {url: $url}) {\n",
    "      ... on CreateArticleSavingRequestSuccess {\n",
    "        articleSavingRequest {\n",
    "          id\n",
    "          status\n",
    "          slug\n",
    "          createdAt\n",
    "          updatedAt\n",
    "          url\n",
    "          errorCode\n",
    "        }\n",
    "      }\n",
    "      ... on CreateArticleSavingRequestError {\n",
    "        errorCodes\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "\"\"\")\n",
    "\n",
    "setLabels = gql(\"\"\"\n",
    "mutation SetLabel($articleId: ID!, $labelIds: [ID!]!) { \n",
    "    setLabels(input: {pageId: $articleId, labelIds: $labelIds}) {\n",
    "        ...on SetLabelsSuccess { \n",
    "            labels { \n",
    "                id\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "updatePageSavedDate =  gql(\"\"\"\n",
    "mutation UpdatePageDate($id: ID!, $date: Date!) {\n",
    "    updatePage(input: {pageId: $id, savedAt: $date, publishedAt: $date}) {\n",
    "        ... on UpdatePageSuccess {\n",
    "            updatedPage {\n",
    "                id\n",
    "                savedAt\n",
    "                publishedAt\n",
    "                title\n",
    "            }\n",
    "        }\n",
    "        ...on UpdatePageError {\n",
    "            errorCodes\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "archivePage = gql(\"\"\"\n",
    "mutation ArchivePage($id: ID!) {\n",
    "    setLinkArchived (input: {linkId: $id, archived: true}) {\n",
    "        ... on ArchiveLinkSuccess {\n",
    "            linkId\n",
    "            message\n",
    "        }\n",
    "        ... on ArchiveLinkError {\n",
    "            message\n",
    "            errorCodes\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "createTag = gql(\"\"\"\n",
    "mutation CreateLabel($nam: String!, $col: String, $desc: String) {\n",
    "  createLabel(input: {name: $nam, color: $col, description: $desc}) {\n",
    "    ... on CreateLabelSuccess {\n",
    "      label {\n",
    "        id\n",
    "        name\n",
    "        color\n",
    "        description\n",
    "        createdAt\n",
    "      }\n",
    "    }\n",
    "    ... on CreateLabelError {\n",
    "      errorCodes\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "getArticleSavingRequest = gql(\"\"\"\n",
    "query ArticleSavingRequest($id: ID!) {\n",
    "    articleSavingRequest(id: $id) {\n",
    "        ... on ArticleSavingRequestSuccess {\n",
    "            articleSavingRequest {\n",
    "              id\n",
    "              status\n",
    "              slug\n",
    "              createdAt\n",
    "              updatedAt\n",
    "              url\n",
    "              errorCode\n",
    "            }\n",
    "        }\n",
    "        ... on ArticleSavingRequestError {\n",
    "            errorCodes\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "getArticle = gql(\"\"\"\n",
    "query GetArticle($slug: String!, $username: String!) {\n",
    "    article(slug: $slug, username: $username) {\n",
    "        ...on ArticleSuccess {\n",
    "            article {\n",
    "                id\n",
    "                title\n",
    "                slug\n",
    "                isArchived\n",
    "                savedAt\n",
    "            }\n",
    "        }\n",
    "        ...on ArticleError {\n",
    "            errorCodes\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\"\"\")\n",
    "                \n",
    "@backoff.on_predicate(\n",
    "    backoff.runtime,\n",
    "    predicate=lambda r: isinstance(r, RequestsHTTPTransport),\n",
    "    value=lambda r: int(r.response_headers[\"RateLimit-Reset\"]) + 1,\n",
    "    jitter=None,\n",
    ")\n",
    "def archiveArticle(articleId): \n",
    "  with create_client() as client: \n",
    "    try: \n",
    "      res = client.execute(archivePage, { 'id': articleId })\n",
    "      return res\n",
    "    except Exception as e:\n",
    "          if (hasattr(e, 'code') and e.code == 429): \n",
    "            return session.transport\n",
    "          print(e)\n",
    "\n",
    "@backoff.on_predicate(\n",
    "    backoff.runtime,\n",
    "    predicate=lambda r: isinstance(r, RequestsHTTPTransport),\n",
    "    value=lambda r: int(r.response_headers[\"RateLimit-Reset\"]) + 1,\n",
    "    jitter=None,\n",
    ")\n",
    "def saveLabels(articleId, labels): \n",
    "    with create_client() as client: \n",
    "      try:\n",
    "        return client.execute(setLabels, {'articleId': articleId, 'labelIds': labels})\n",
    "      except Exception as e:\n",
    "          if (hasattr(e, 'code') and e.code == 429): \n",
    "            return session.transport\n",
    "          print(e)\n",
    "\n",
    "@backoff.on_predicate(\n",
    "    backoff.runtime,\n",
    "    predicate=lambda r: isinstance(r, RequestsHTTPTransport),\n",
    "    value=lambda r: int(r.response_headers[\"RateLimit-Reset\"]) + 1,\n",
    "    jitter=None,\n",
    ")\n",
    "def saveArticle(article):\n",
    "    with create_client() as client: \n",
    "      try: \n",
    "        logging.info(f\"Saving article {article['href']}\")\n",
    "        url = article['href']\n",
    "        tags = article['tags']\n",
    "        # First createArticleSavingRequest\n",
    "        r = client.execute(createArticle, variable_values={'url': url})\n",
    "        id = r['createArticleSavingRequest']['articleSavingRequest']['id']\n",
    "        status = r['createArticleSavingRequest']['articleSavingRequest']['status']\n",
    "        \n",
    "        if len(tags) != 0: \n",
    "            saveLabels(id, tags)\n",
    "                            \n",
    "        # Return the article with the id of the saved document\n",
    "        return {**article, 'id': id, 'status': status, }\n",
    "      except Exception as e:\n",
    "          if (hasattr(e, 'code') and e.code == 429): \n",
    "            return session.transport\n",
    "          # I don't know why this happens and I will figure it out later.\n",
    "          print(e)\n",
    "\n",
    "@backoff.on_predicate(\n",
    "    backoff.runtime,\n",
    "    predicate=lambda r: isinstance(r, RequestsHTTPTransport),\n",
    "    value=lambda r: int(r.response_headers[\"RateLimit-Reset\"]) + 1,\n",
    "    jitter=None,\n",
    ")\n",
    "def updateArticleTimeAfterProcessing(articleId, date = None):\n",
    "    with create_client() as client: \n",
    "        try: \n",
    "            if date is not None: \n",
    "              # Wait a bit, it seems there's a race condition.\n",
    "              res = client.execute(updatePageSavedDate, {\n",
    "                  'id': articleId,\n",
    "                  'date': date,\n",
    "              })\n",
    "              return res\n",
    "\n",
    "        except Exception as e:\n",
    "          if (hasattr(e, 'code') and e.code == 429): \n",
    "            return session.transport\n",
    "          \n",
    "          # I don't know why this happens and I will figure it out later.\n",
    "          raise\n",
    "\n",
    "@backoff.on_predicate(\n",
    "    backoff.runtime,\n",
    "    predicate=lambda r: isinstance(r, RequestsHTTPTransport),\n",
    "    value=lambda r: int(r.response_headers[\"RateLimit-Reset\"]) + 1,\n",
    "    jitter=None,\n",
    ")\n",
    "def articleSavingRequest(articleId):\n",
    "    with create_client() as client:\n",
    "        try: \n",
    "            # Wait a bit, it seems there's a race condition.\n",
    "            res = client.execute(getArticleSavingRequest, {\n",
    "                'id': articleId,\n",
    "            })\n",
    "\n",
    "            return res['articleSavingRequest']['articleSavingRequest']\n",
    "        except Exception as e:\n",
    "          if (hasattr(e, 'code') and e.code == 429): \n",
    "            return session.transport\n",
    "          \n",
    "          # I don't know why this happens and I will figure it out later.\n",
    "          raise\n",
    "\n",
    "@backoff.on_predicate(\n",
    "    backoff.runtime,\n",
    "    predicate=lambda r: isinstance(r, RequestsHTTPTransport),\n",
    "    value=lambda r: int(r.response_headers[\"RateLimit-Reset\"]) + 1,\n",
    "    jitter=None,\n",
    ")\n",
    "def getArticleInfo(slug):\n",
    "    with create_client() as client:\n",
    "        try: \n",
    "            # Wait a bit, it seems there's a race condition.\n",
    "            res = client.execute(getArticle, {\n",
    "                'slug': slug,\n",
    "                'username': USERNAME,\n",
    "            })\n",
    "\n",
    "            return res['article']['article']\n",
    "        except Exception as e:\n",
    "          if (hasattr(e, 'code') and e.code == 429): \n",
    "            return session.transport\n",
    "          \n",
    "          # I don't know why this happens and I will figure it out later.\n",
    "          raise\n",
    "\n",
    "getArticleInfo(\"https-www-garbageday-email-p-when-the-traffic-firehose-is-pointe-1883f6d08f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_to_article(row):  \n",
    "   return { \n",
    "      \"id\": row[0],\n",
    "      \"read\": bool(row[1]),\n",
    "      \"time_added\": row[2],\n",
    "      \"tags\": [tagIds[tag] for tag in json.loads(row[3]) if tag != ''],\n",
    "      \"href\": row[4]\n",
    "   }\n",
    "\n",
    "all_articles = [row_to_article(row) for row in cursor.execute('select * from articles').fetchall()]\n",
    "unsaved_articles = list(filter(lambda article: article['id'] is None, all_articles)) \n",
    "saved_articles = list(filter(lambda article: article['id'] is not None, all_articles))\n",
    "\n",
    "saved_articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thread Pool executors fall a bit behind on our usage, so I will create a custom one\n",
    "\n",
    "It has a number of `worker` threads that just spin on a queue of functions executing the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import pytz\n",
    "\n",
    "def checkTask(article):\n",
    "    \"\"\" Runs a check agains Omnivore, if the article is processed updates its date,\n",
    "    Returns the new article object\n",
    "    \"\"\"\n",
    "    asr = articleSavingRequest(article['id'])\n",
    "    article['status'] = asr['status']\n",
    "\n",
    "    if article['status'] != 'SUCCEEDED':\n",
    "        print(f\"Retrying article\", asr)\n",
    "        return article\n",
    "\n",
    "    updateArticleTimeAfterProcessing(article['id'], article['time_added'])\n",
    "    if article['read']:\n",
    "        archiveArticle(article['id'])\n",
    "    \n",
    "    omnArt = getArticleInfo(asr['slug'])\n",
    "\n",
    "    dtexpected = datetime.fromisoformat(article['time_added']).replace(tzinfo=pytz.UTC)\n",
    "    dtgot = datetime.fromisoformat(omnArt['savedAt'])\n",
    "    \n",
    "    c1 = article['read'] == omnArt['isArchived']\n",
    "    c2 = abs((dtexpected - dtgot).total_seconds()) < 3600\n",
    "    if not c1 or not c2:\n",
    "        print(f\"Data not changed, retrying article {omnArt['slug']}, \", end=\"\")\n",
    "        if not c1:\n",
    "            print(f\"Incorrect archive status. expected {article['read']}, got {omnArt['isArchived']}. \", end=\"\")\n",
    "        if not c2:\n",
    "            print(f\"datetime not changed. expected {dtexpected}, got {dtgot}\", end=\"\")\n",
    "        print()\n",
    "        \n",
    "        article['status'] = '_RETRY'\n",
    "        return article\n",
    "    \n",
    "    return article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(unchecked_articles.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from multiprocessing.pool import ThreadPool\n",
    "from tqdm.notebook import tqdm\n",
    "from threading import Lock\n",
    "import time\n",
    "\n",
    "tqdm_custom = lambda desc: tqdm(desc=desc, total=len(unsaved_articles))\n",
    "\n",
    "with (ThreadPoolExecutor(PARALLEL_API_CALL_SIZE) as executor,\n",
    "      tqdm_custom('Submit') as pbar1,\n",
    "      tqdm_custom('Done') as pbar2):\n",
    "\n",
    "    try:\n",
    "        unchecked_articles = {}\n",
    "\n",
    "        # TODO: Load from db and repopulate unsaved and unchecked articles\n",
    "        fmap1 = { executor.submit(saveArticle, article) : article for article in unsaved_articles }\n",
    "        for f in as_completed(fmap1):\n",
    "            newarticle = f.result()\n",
    "            pbar1.update()\n",
    "            unchecked_articles[executor.submit(checkTask, newarticle)] = newarticle\n",
    "            # Save state to db if needed\n",
    "\n",
    "        while unchecked_articles:\n",
    "            for f in as_completed(unchecked_articles):\n",
    "                newarticle = f.result()\n",
    "                if newarticle['status'] == 'SUCCEEDED': # Task completed\n",
    "                    pbar2.update()\n",
    "                elif newarticle['status'] == 'PROCESSING' or newarticle['status'] == '_RETRY':\n",
    "                    unchecked_articles[executor.submit(checkTask, newarticle)] = newarticle\n",
    "                else:\n",
    "                    raise ValueError(f\"Unknown article status: {newarticle['status']}\")\n",
    "                unchecked_articles.pop(f)\n",
    "    except KeyboardInterrupt:\n",
    "        executor.shutdown(cancel_futures=True)\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
